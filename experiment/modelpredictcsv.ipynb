{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f42ac0e9-2a9a-478e-be47-35002390a00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with subject 114\n",
      "114 trial_435_7030.csv already exists\n",
      "Matches: True\n",
      "114_datashuffle.csv already exists\n",
      "Matches: True\n",
      "114 train_100_7030.csv already exists\n",
      "Matches: True\n",
      "114 select_168_7030.csv already exists\n",
      "Matches: True\n",
      "0.6866666666666666\n",
      "Matches: True\n",
      "0.7416666666666667\n",
      "Matches: True\n",
      "0.7\n",
      "Matches: True\n",
      "0.6083333333333333\n",
      "Matches: True\n",
      "0.6333333333333333\n",
      "Matches: True\n",
      "0.6166666666666667\n",
      "Matches: True\n"
     ]
    }
   ],
   "source": [
    "'''creates subject specific csvs'''\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations, permutations\n",
    "import os\n",
    "\n",
    "# subject = int(input('Enter Subject Number: '))\n",
    "def subject_csv_read(subject):\n",
    "    np.random.seed(subject)\n",
    "    currentPath = os.getcwd()\n",
    "    dirpath = os.path.join(currentPath, '../data/Subject' +str(subject))\n",
    "\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "        \n",
    "    ## Check Session 1-2 dfs\n",
    "    df_list = ['trial_435_7030.csv','train_100_7030.csv','select_168_7030.csv']\n",
    "    for fn in df_list:\n",
    "        fp = f'../inc_csvs/{fn}'\n",
    "        df = pd.read_csv(fp)\n",
    "        df = df.sample(frac=1).reset_index(drop=False)\n",
    "        df2 = df.copy()\n",
    "        subdf = os.path.join(os.getcwd(), '../data/' + 'Subject' + str(subject)+ '/' +'subject'+str(subject)+'_'+fn)\n",
    "        try: ###check for shuffled df for the model to run through eventually\n",
    "            pd.read_csv(subdf)\n",
    "            print(f'{subject} {fn} already exists')\n",
    "        except FileNotFoundError:\n",
    "            df2.to_csv(subdf,index=False)\n",
    "        print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "        if fn == df_list[0]:\n",
    "            subdf = os.path.join(os.getcwd(), '../data/' + 'Subject' + str(subject)+ '/' +str(subject)+'_datashuffle.csv')\n",
    "            try: ###check for shuffled df for the model to run through eventually\n",
    "                pd.read_csv(subdf)\n",
    "                print(f'{subject}_datashuffle.csv already exists')\n",
    "            except FileNotFoundError:\n",
    "                df2.to_csv(subdf,index=False)\n",
    "            print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "            \n",
    "        \n",
    "    ## Check Session 1-2 dfs\n",
    "    df_list = ['Train_7525.csv','Prac1_7525.csv','Prac2_7525.csv']\n",
    "    start = list(combinations(['Workclass','Highest Degree','Marital Status','Race','Gender','Occupation','Hours per Week','Age'],3))#,'Years of Education'],3)) \n",
    "    np.random.shuffle(start)    \n",
    "    for fn in df_list:\n",
    "        preds = []\n",
    "        confs = []\n",
    "        fp = f'../inc_csvs/{fn}'\n",
    "        df = pd.read_csv(fp)\n",
    "        df = df.sample(frac=1).reset_index(drop=False)\n",
    "        df2 = df.copy()\n",
    "        # print(df.head())\n",
    "        if len(start) < len(df):\n",
    "            start = start * int(np.ceil((len(df)/len(start))))\n",
    "        for ind,row in df.iterrows():\n",
    "            combo = sorted(start[ind])\n",
    "            row = pd.DataFrame(row[list(combo)]).T\n",
    "            with open('../model_work/models/'+'_'.join(combo)+'.pkl', 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            # print('./py_models/'+'_'.join(combo)+'_model.pkl')\n",
    "            ml_res = model.predict(row)[0]\n",
    "            ml_prob = model.predict_proba(row)[0][ml_res]\n",
    "            # print(ml_res,ml_prob)\n",
    "            preds.append(ml_res)\n",
    "            confs.append(ml_prob)\n",
    "        df2['ML Pred'] = preds\n",
    "        df2['ML Conf'] = confs\n",
    "        print((preds==df2['Income']).sum()/len(df2))\n",
    "        subdf = os.path.join(os.getcwd(), '../data/' + 'Subject' + str(subject)+ '/' +'subject'+str(subject)+'_'+fn)\n",
    "        try: ###check for shuffled df for the model to run through eventually\n",
    "            pd.read_csv(subdf)\n",
    "            print(f'{subject} {fn} already exists')\n",
    "        except FileNotFoundError:\n",
    "            df2.to_csv(subdf,index=False)\n",
    "        print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "        # print(pd.read_csv(subdf)['index'],df2['index'])\n",
    "\n",
    "def full_model_csv_read(subject):\n",
    "    np.random.seed(subject)\n",
    "    currentPath = os.getcwd()\n",
    "    dirpath = os.path.join(currentPath, '../data/Subject' +str(subject))\n",
    "\n",
    "    if not os.path.isdir(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "        \n",
    "    # ## Check Session 1-2 dfs\n",
    "    # df_list = ['trial_435_7030.csv','train_45_7030.csv','select_168_7030.csv']\n",
    "    # for fn in df_list:\n",
    "    #     df = pd.read_csv(fn)\n",
    "    #     df = df.sample(frac=1).reset_index(drop=False)\n",
    "    #     df2 = df.copy()\n",
    "    #     subdf = os.path.join(os.getcwd(), 'data/' + 'Subject' + str(subject)+ '/' +'subject'+str(subject)+'_'+fn)\n",
    "    #     try: ###check for shuffled df for the model to run through eventually\n",
    "    #         pd.read_csv(subdf)\n",
    "    #         print(f'{subject} {fn} already exists')\n",
    "    #     except FileNotFoundError:\n",
    "    #         df2.to_csv(subdf,index=False)\n",
    "    #     print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "    #     if fn == df_list[0]:\n",
    "    #         with open('./py_models/'+'fullmodel.pkl', 'rb') as f:\n",
    "    #             model = pickle.load(f)\n",
    "    #         x = \n",
    "    #         subdf = os.path.join(os.getcwd(), 'data/' + 'Subject' + str(subject)+ '/' +str(subject)+'_datashuffle.csv')\n",
    "    #         try: ###check for shuffled df for the model to run through eventually\n",
    "    #             pd.read_csv(subdf)\n",
    "    #             print(f'{subject}_datashuffle.csv already exists')\n",
    "    #         except FileNotFoundError:\n",
    "    #             df2.to_csv(subdf,index=False)\n",
    "    #         print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "            \n",
    "    ## Check Session 1-2 dfs\n",
    "    attributes = ['Workclass','Highest Degree','Marital Status','Race','Gender','Occupation','Hours per Week','Age','Native Country']\n",
    "    df_list = ['Train_7525.csv','Prac1_7525.csv','Prac2_7525.csv']\n",
    "    start = list(combinations(['Workclass','Highest Degree','Marital Status','Race','Gender','Occupation','Hours per Week','Age'],3))#,'Years of Education'],3)) \n",
    "    np.random.shuffle(start)    \n",
    "    for fn in df_list:\n",
    "        preds = []\n",
    "        confs = []\n",
    "        fp = f'../inc_csvs/{fn}'\n",
    "        df = pd.read_csv(fp)\n",
    "        df = df.sample(frac=1).reset_index(drop=False)\n",
    "        df2 = df.copy()\n",
    "        # print(df.head())\n",
    "        if len(start) < len(df):\n",
    "            start = start * int(np.ceil((len(df)/len(start))))\n",
    "        for ind,row in df.iterrows():\n",
    "            combo = sorted(start[ind])\n",
    "            # row = pd.DataFrame(row[list(combo)]).T\n",
    "            row = pd.DataFrame(row[attributes]).T\n",
    "            for i in [i for i in attributes if i not in combo]:\n",
    "                if i in ['Hours per Week','Age']:\n",
    "                    row[i] = np.nan\n",
    "                else:\n",
    "                    row[i] = ''\n",
    "            # row = pd.DataFrame(row.drop(['Income','Income Adjust','income-actual','ML Pred','ML Conf'])).T\n",
    "            # print(row)\n",
    "            with open('../model_work/models/'+'fullmodel.pkl', 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            ml_res = model.predict(row)[0]\n",
    "            ml_prob = model.predict_proba(row)[0][int(ml_res)]\n",
    "            preds.append(int(ml_res))\n",
    "            confs.append(ml_prob)\n",
    "        df2['ML Pred'] = preds\n",
    "        df2['ML Conf'] = confs\n",
    "        print((preds==df2['Income']).sum()/len(df2))\n",
    "        subdf = os.path.join(os.getcwd(), '../data/' + 'Subject' + str(subject)+ '/' +'subject'+str(subject)+'_fullmodel_'+fn)\n",
    "        try: ###check for shuffled df for the model to run through eventually\n",
    "            pd.read_csv(subdf)\n",
    "            print(f'Full Model {subject} {fn} already exists')\n",
    "        except FileNotFoundError:\n",
    "            df2.to_csv(subdf,index=False)\n",
    "        print('Matches:',(pd.read_csv(subdf)['index'] == df2['index']).all())\n",
    "if __name__==\"__main__\":\n",
    "    sub = 114\n",
    "    print(f'Testing with subject {sub}')\n",
    "    subject_csv_read(sub)\n",
    "    full_model_csv_read(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8e4d1-11b7-4ac8-95d6-a70a19c468ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
