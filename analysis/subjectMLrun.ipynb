{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29a0bdb-61ce-4cef-bc6a-06bd2ca053de",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Concatenates both sessions and saves csvs of indivdual sessions and combined session (needs two sessions to run)\n",
    "requires behavior files from subject and segmented eeg file (segment_edit) or scanned eeg file (scan_responses)'''\n",
    "## Import necessary functions\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import ast\n",
    "import os\n",
    "from hdf5storage import loadmat\n",
    "#from tkinter import filedialog #Only use if using file selecter\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5bee78-572c-420f-8c00-8cbcaa75d268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Trial 130\n"
     ]
    }
   ],
   "source": [
    "'''Produce csv files of subject for session and full\n",
    "ONLY RUN if do not have Subject{sub}Full.csv and/or Session_#_Dataset.csv '''\n",
    "for sub in ['105']:#,'3','4','5','6']: ##subject\n",
    "    file_path = f'../data/Subject{sub}/{sub}_datashuffle.csv'\n",
    "    ind_df =  pd.read_csv(file_path)\n",
    "    # inds =  np.array(ind_df['Unnamed: 0'])\n",
    "    inds =  np.array(ind_df['index'])\n",
    "    # mlresponsearray = np.array(ind_df['income-pred'])\n",
    "    mlresponsearray = np.array(ind_df['ML Pred'])\n",
    "    cleanlst = []\n",
    "    for ses in [1,2]:\n",
    "    # for ses in [1]:\n",
    "        # path = f'segmented/{sub}SS{ses}_segmented.hdf.mat'\n",
    "        path = f'./scanned/{sub}SS{ses}_scanned.hdf.mat'\n",
    "        cleanlst.append(path)\n",
    "    ipad = 0\n",
    "    for ses,f in enumerate(cleanlst):\n",
    "        subinf = loadmat(f)\n",
    "        ses = str(ses+1)\n",
    "        if ses == '2':\n",
    "            ipad = answerarray.shape[0]\n",
    "        responsearray = subinf['choice']\n",
    "        # print(responsearray)\n",
    "        answerarray = subinf['answer']\n",
    "        #response = outdict['cedrus_response']\n",
    "        featsarray = subinf['ordered_features']\n",
    "        mlresponsearray = subinf['model_response']\n",
    "        #mlresponsearray = np.array(subinf['model_response'].shape)\n",
    "        rows = []\n",
    "        for i in range(answerarray.shape[0]):\n",
    "            if responsearray[i] == -1:\n",
    "                print(f'Invalid Trial {i+ipad}')\n",
    "                continue\n",
    "            row = {}\n",
    "            feats = featsarray[i*10:i*10+9]\n",
    "            feord = []\n",
    "            for fe in feats:\n",
    "                key,val = fe.split(': ')\n",
    "                row[key] = val\n",
    "                feord.append(key)\n",
    "            row['Response'] = responsearray[i]\n",
    "            row['Real Answer'] = answerarray[i]\n",
    "            row['Model'] = mlresponsearray[i] ## first pass error in collection of model response run last block in script to fix\n",
    "            row['Original Ind'] = inds[i+ipad]\n",
    "            row['Feat Order'] = np.array(feord)\n",
    "            #print(i + ipad)\n",
    "            rows.append(row)\n",
    "\n",
    "\n",
    "        new = pd.DataFrame.from_dict(rows, orient='columns')\n",
    "        fl = f'../data/Subject{sub}/{sub}_Session_{ses}_Dataset.csv'\n",
    "        new.to_csv(fl,index = False)\n",
    "\n",
    "#     ### combine both sessions\n",
    "    csv1 = f'../data/Subject{sub}/{sub}_Session_1_Dataset.csv'\n",
    "    csv2 = f'../data/Subject{sub}/{sub}_Session_2_Dataset.csv'\n",
    "    df1 = pd.read_csv(csv1)\n",
    "    df2 = pd.read_csv(csv2)\n",
    "    dffull = pd.concat([df1,df2],axis = 0)\n",
    "    fn = f'../data/Subject{sub}/Subject{sub}Full.csv'\n",
    "    dffull.to_csv(fn,index = False) ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178e7fd9-9e18-42c6-a2a0-012b4045f960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 434\n",
      "Number of features: 9\n",
      "Number of categorical features: 7\n",
      "Number of numerical features: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import partial_dependence\n",
    "min_samples_leaf = 20 #default = 1\n",
    "max_depth = 3 #optimizes for experiment dataset; default = None\n",
    "max_leaf_nodes = 31 #default = 31\n",
    "test_size = 0.25\n",
    "sub = '105'\n",
    "\n",
    "## Import Data\n",
    "#### run full dataset, will not work well with one session\n",
    "file_path = f'../data/Subject{sub}/Subject{sub}Full.csv'\n",
    "title = file_path.split('/')[2]\n",
    "sub_df =  pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "y = sub_df[['Response']].copy().values.squeeze()\n",
    "y_real = sub_df[['Real Answer']].copy().values.squeeze()\n",
    "try:\n",
    "    numFeatures = list(sub_df.select_dtypes(include = 'number').drop(labels=['Response', 'Real Answer','Model','Original Ind'], axis=1))\n",
    "except:\n",
    "    print('Model not in df')\n",
    "    numFeatures = list(sub_df.select_dtypes(include = 'number').drop(labels=['Response', 'Real Answer','Original Ind'], axis=1))\n",
    "catFeatures = list(sub_df.select_dtypes(include = object).drop(labels=['Feat Order'], axis=1))\n",
    "x = sub_df[catFeatures + numFeatures].copy()\n",
    "### Mark categorical features\n",
    "x[catFeatures] = x[catFeatures].astype(\"category\")\n",
    "\n",
    "numFeatures.sort()\n",
    "catFeatures.sort()\n",
    "### Check shape of feature data set\n",
    "n_categorical_features = x.select_dtypes(include=\"category\").shape[1]\n",
    "n_numerical_features = x.select_dtypes(include=\"number\").shape[1]\n",
    "print(f\"Number of samples: {x.shape[0]}\")\n",
    "print(f\"Number of features: {x.shape[1]}\")\n",
    "print(f\"Number of categorical features: {n_categorical_features}\")\n",
    "print(f\"Number of numerical features: {n_numerical_features}\")\n",
    "strainlst = []\n",
    "stestlst = []\n",
    "mtrainlst = []\n",
    "mtestlst = []\n",
    "#yproblst = []\n",
    "\n",
    "\n",
    "    \n",
    "for it in range(100):\n",
    "    rand_state = it\n",
    "    ### Create test and train set from existing dataframe\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=rand_state)\n",
    "    X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(x, y_real, test_size=test_size, random_state=rand_state)\n",
    "    ## Process categorical features for OneHotEncoder\n",
    "    one_hot_encoder = make_column_transformer(\n",
    "        (\n",
    "            OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n",
    "            make_column_selector(dtype_include=\"category\"),\n",
    "        ),\n",
    "        verbose_feature_names_out = False,\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "    hist_one_hot = make_pipeline(\n",
    "         one_hot_encoder, HistGradientBoostingClassifier(random_state=42)\n",
    "    )\n",
    "    hist_one_hot = Pipeline([\n",
    "        (\"preprocess\",one_hot_encoder), (\"classifier\", HistGradientBoostingClassifier(random_state=rand_state)),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    '''Model that predicts subject's responses'''\n",
    "    ## Fit training set to model\n",
    "    model = hist_one_hot.set_params(classifier__min_samples_leaf=min_samples_leaf,classifier__max_depth = max_depth, classifier__max_leaf_nodes = max_leaf_nodes).fit(X_train, y_train)\n",
    "\n",
    "    train_result = permutation_importance(\n",
    "            model, X_train, y_train, n_repeats=10, random_state=rand_state, n_jobs=2\n",
    "            )\n",
    "    test_results = permutation_importance(\n",
    "            model, X_test, y_test, n_repeats=10, random_state=rand_state, n_jobs=2\n",
    "            )\n",
    "\n",
    "    sorted_importances_idx = train_result.importances_mean.argsort()\n",
    "\n",
    "    train_importances = pd.DataFrame(\n",
    "            train_result.importances[sorted_importances_idx].T,\n",
    "            columns=x.columns[sorted_importances_idx],\n",
    "            )\n",
    "    test_importances = pd.DataFrame(\n",
    "            test_results.importances[sorted_importances_idx].T,\n",
    "            columns=x.columns[sorted_importances_idx],\n",
    "            )\n",
    "    strainlst.append(train_importances)\n",
    "    stestlst.append(test_importances)\n",
    "\n",
    "    '''Model using real answers same order and valid trials as model predicting responses'''\n",
    "\n",
    "    model = hist_one_hot.set_params(classifier__min_samples_leaf=min_samples_leaf,classifier__max_depth = max_depth, classifier__max_leaf_nodes = max_leaf_nodes).fit(X_train_real, y_train_real)\n",
    "\n",
    "\n",
    "    train_result = permutation_importance(\n",
    "            model, X_train_real, y_train_real, n_repeats=10, random_state=rand_state, n_jobs=2\n",
    "            )\n",
    "    test_results = permutation_importance(\n",
    "            model, X_test_real, y_test_real, n_repeats=10, random_state=rand_state, n_jobs=2\n",
    "            )\n",
    "\n",
    "    sorted_importances_idx = train_result.importances_mean.argsort()\n",
    "\n",
    "    train_importances = pd.DataFrame(\n",
    "            train_result.importances[sorted_importances_idx].T,\n",
    "            columns=x.columns[sorted_importances_idx],\n",
    "            )\n",
    "    test_importances = pd.DataFrame(\n",
    "            test_results.importances[sorted_importances_idx].T,\n",
    "            columns=x.columns[sorted_importances_idx],\n",
    "            )\n",
    "    mtrainlst.append(train_importances)\n",
    "    mtestlst.append(test_importances)\n",
    "    #yproblst.append(y_prob)\n",
    "\n",
    "\n",
    "'''Model that predicts subject's responses'''\n",
    "subdata = {}\n",
    "rand_state = 42\n",
    "## Fit training set to model\n",
    "model = hist_one_hot.set_params(classifier__min_samples_leaf=min_samples_leaf,classifier__max_depth = max_depth, classifier__max_leaf_nodes = max_leaf_nodes).fit(X_train, y_train)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_repeats=10, random_state=rand_state)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "subdata['Sub Test Acc Mean'] = np.mean(n_scores)\n",
    "subdata['Sub Test Acc STD'] = np.std(n_scores)\n",
    "n_scores = cross_val_score(model, X_train_real, y_train_real, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "subdata['Sub Train Acc Mean'] = np.mean(n_scores)\n",
    "subdata['Sub Train Acc STD'] = np.std(n_scores)\n",
    "\n",
    "## empty data frame to use for appending\n",
    "df=pd.DataFrame()\n",
    "#looping through each item in list and appending to empty data frame\n",
    "for i in strainlst:\n",
    "    df = df.append(i)\n",
    "# group by and calculating mean on index\n",
    "train_importances = df.groupby(level=0).mean()\n",
    "train_importances = train_importances.sort_index(axis = 1)\n",
    "\n",
    "## empty data frame to use for appending\n",
    "df=pd.DataFrame()\n",
    "#looping through each item in list and appending to empty data frame\n",
    "for i in stestlst:\n",
    "    df = df.append(i)\n",
    "# group by and calculating mean on index\n",
    "test_importances = df.groupby(level=0).mean()\n",
    "test_importances = test_importances.sort_index(axis = 1)\n",
    "    \n",
    "    \n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = test_importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(f\"Permutation Importances Test Set (Subject {sub})\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.figure.tight_layout()\n",
    "fn = f'../data/Subject{sub}/{sub}Subject_Test_Perm_Imp.png'\n",
    "# plt.savefig(fn,format = 'png')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = train_importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(f\"Permutation Importances Train Set(Subject {sub})\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.figure.tight_layout()\n",
    "fn = f'../data/Subject{sub}/{sub}Subject_Train_Perm_Imp2.png'\n",
    "# plt.savefig(fn,format = 'png')\n",
    "plt.show()\n",
    "test_importances.to_csv('../data/Subject'+sub+'/test_imp_'+sub+'.csv')\n",
    "train_importances.to_csv('../data/Subject'+sub+'/train_imp_'+sub+'.csv')\n",
    "\n",
    "### partial dependence plots\n",
    "train_med = train_importances.drop(['Hours per Week','Age'],axis = 1).max(axis=0).to_dict()\n",
    "train_per = list(train_med.values())\n",
    "train_per.sort()\n",
    "train_per = train_per[-3:]\n",
    "topfeat = []\n",
    "\n",
    "for per in train_per:\n",
    "    per = list(train_med.keys())[list(train_med.values()).index(per)]\n",
    "    topfeat.append(per)\n",
    "    \n",
    "from itertools import combinations\n",
    "combos = combinations(topfeat, 2)\n",
    "combos = [i for i in combos]\n",
    "\n",
    "common_params = {\n",
    "    \"subsample\": 100,\n",
    "    \"n_jobs\": 2,\n",
    "    \"grid_resolution\": 20,\n",
    "    \"random_state\": rand_state,\n",
    "}\n",
    "\n",
    "print(\"Computing partial dependence plots...\")\n",
    "features_info = {\n",
    "    # features of interest\n",
    "    \"features\": numFeatures+catFeatures,#topfeat,\n",
    "    # type of partial dependence plot\n",
    "    \"kind\": \"average\",\n",
    "    # information regarding categorical features\n",
    "    \"categorical_features\": catFeatures,\n",
    "}\n",
    "\n",
    "sub_pd = {}\n",
    "for i in X_train.columns:\n",
    "    sub_pardep = partial_dependence(\n",
    "        model, X = X_train, features = i,categorical_features = catFeatures, grid_resolution = 20)\n",
    "    sub_pd[i] = dict(sub_pardep)\n",
    "for depcat in ['Age','Hours per Week']:\n",
    "    newdict = {}\n",
    "    avlist = []\n",
    "    vallist = []\n",
    "    # print(sub_pd[depcat]['average'])\n",
    "    for bavg,bval in zip(sub_pd[depcat]['average'],sub_pd[depcat]['values']):\n",
    "        for bavg,bval in zip(bavg,bval):\n",
    "            avlist.append(bavg)\n",
    "            vallist.append(round(bval,0))\n",
    "    newdict['average'] = np.array([avlist])\n",
    "    newdict['values'] = np.array([vallist])\n",
    "    sub_pd[depcat] = newdict\n",
    "        \n",
    "bias = sum(y_train)/len(y_train)    \n",
    "\n",
    "_, ax = plt.subplots(ncols=3, nrows=3, figsize=(30, 30), constrained_layout=True)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].axhline(y = bias, color = 'k', linestyle = '--')\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_train,\n",
    "    **features_info,\n",
    "    ax=ax,\n",
    "    **common_params,\n",
    ")\n",
    "\n",
    "\n",
    "_ = display.figure_.suptitle(\n",
    "    f\"Subject {sub} Partial dependence of the census data\",\n",
    "    fontsize=40,\n",
    ")\n",
    "fn = f'../data/Subject{sub}/{sub}ValueDependence.png'\n",
    "# plt.savefig(fn,format ='png', bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Computing partial dependence corrs...\")\n",
    "features_info = {\n",
    "    # features of interest\n",
    "    \"features\": [('Age','Hours per Week')] + combos,#topfeat,\n",
    "    # type of partial dependence plot\n",
    "    \"kind\": \"average\",\n",
    "    # information regarding categorical features\n",
    "    \"categorical_features\": catFeatures,\n",
    "}\n",
    "\n",
    "_, ax = plt.subplots(ncols=2, nrows=2, figsize=(20, 20), constrained_layout=True)\n",
    "#for i in range(2):\n",
    "#    for j in range(2):\n",
    "#        ax[i,j].axhline(y = 0.5, color = 'k', linestyle = '--')\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_train,\n",
    "    **features_info,\n",
    "    ax=ax,\n",
    "    **common_params,\n",
    ")\n",
    "_ = display.figure_.suptitle(\n",
    "    f\"Subject {sub} Partial dependence pairings\",\n",
    "    fontsize=40,\n",
    ")\n",
    "fn = f'../data/Subject{sub}/{sub}PairDependence.png'\n",
    "#plt.savefig(fn,format ='png', bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for fold, (train, test) in enumerate(cv.split(x, y)):  ##############################################################################\n",
    "    model.fit(x.iloc[train], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        model,\n",
    "        x.iloc[test],\n",
    "        y[test],\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability (On Subject)\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.gcf()\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles = handles[-3:]\n",
    "labels = labels[-3:]\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "fn =f'../data/Subject{sub}/{sub}_ROC_Curve.png'\n",
    "# plt.savefig(fn,format = 'png',dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "subdata['Sub Mean TPR'] = mean_tpr\n",
    "subdata['Sub Mean AUC'] = mean_auc\n",
    "subdata['Sub STD AUC'] = std_auc\n",
    "subdata['Sub STD TPR'] = std_tpr\n",
    "subdata['Sub Upper TPR'] = tprs_upper\n",
    "subdata['Sub Lower TPR'] = tprs_lower\n",
    "subdata['Sub PD'] = sub_pd\n",
    "subdata['Sub bias'] = bias\n",
    "\n",
    "\n",
    "\n",
    "'''Model using real answers same order and valid trials as model predicting responses'''\n",
    "model = hist_one_hot.set_params(classifier__min_samples_leaf=min_samples_leaf,classifier__max_depth = max_depth, classifier__max_leaf_nodes = max_leaf_nodes).fit(X_train_real, y_train_real)\n",
    "\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_repeats=10, random_state=rand_state)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X_test_real, y_test_real, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "subdata['ML Test Acc Mean'] = np.mean(n_scores)\n",
    "subdata['ML Test Acc STD'] = np.std(n_scores)\n",
    "n_scores = cross_val_score(model, X_train_real, y_train_real, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "subdata['ML Train Acc Mean'] = np.mean(n_scores)\n",
    "subdata['ML Train Acc STD'] = np.std(n_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## empty data frame to use for appending\n",
    "df=pd.DataFrame()\n",
    "#looping through each item in list and appending to empty data frame\n",
    "for i in mtrainlst:\n",
    "    df = df.append(i)\n",
    "# group by and calculating mean on index\n",
    "train_importances = df.groupby(level=0).mean()\n",
    "train_importances = train_importances.sort_index(axis = 1)\n",
    "\n",
    "## empty data frame to use for appending\n",
    "df=pd.DataFrame()\n",
    "#looping through each item in list and appending to empty data frame\n",
    "for i in mtestlst:\n",
    "    df = df.append(i)\n",
    "\n",
    "# group by and calculating mean on index\n",
    "test_importances = df.groupby(level=0).mean()\n",
    "test_importances = test_importances.sort_index(axis = 1)\n",
    "\n",
    "### partial dependence plots\n",
    "\n",
    "\n",
    "train_med = train_importances.drop(['Hours per Week','Age'],axis = 1).max(axis=0).to_dict()\n",
    "train_per = list(train_med.values())\n",
    "train_per.sort()\n",
    "train_per = train_per[-3:]\n",
    "topfeat = []\n",
    "\n",
    "for per in train_per:\n",
    "    per = list(train_med.keys())[list(train_med.values()).index(per)]\n",
    "    topfeat.append(per)\n",
    "\n",
    "combos = combinations(topfeat, 2)\n",
    "combos = [i for i in combos]\n",
    "\n",
    "common_params = {\n",
    "    \"subsample\": 100,\n",
    "    \"n_jobs\": 2,\n",
    "    \"grid_resolution\": 20,\n",
    "    \"random_state\": rand_state,\n",
    "}\n",
    "\n",
    "print(\"Computing partial dependence plots...\")\n",
    "features_info = {\n",
    "    # features of interest\n",
    "    \"features\": numFeatures+catFeatures,#topfeat,\n",
    "    # type of partial dependence plot\n",
    "    \"kind\": \"average\",\n",
    "    # information regarding categorical features\n",
    "    \"categorical_features\": catFeatures,\n",
    "}\n",
    "\n",
    "ml_pd = {}\n",
    "for i in X_train_real.columns:\n",
    "    ml_pardep = partial_dependence(\n",
    "        model, X = X_train_real, features = i,categorical_features = catFeatures, grid_resolution = 20)\n",
    "    ml_pd[i] = dict(ml_pardep)\n",
    "for depcat in ['Age','Hours per Week']:\n",
    "    newdict = {}\n",
    "    avlist = []\n",
    "    vallist = []\n",
    "    # print(ml_pd[depcat]['average'])\n",
    "    for bavg,bval in zip(ml_pd[depcat]['average'],ml_pd[depcat]['values']):\n",
    "        for bavg,bval in zip(bavg,bval):\n",
    "            avlist.append(bavg)\n",
    "            vallist.append(round(bval,0))\n",
    "    newdict['average'] = np.array([avlist])\n",
    "    newdict['values'] = np.array([vallist])\n",
    "    ml_pd[depcat] = newdict\n",
    "bias = sum(y_train_real)/len(y_train_real)\n",
    "\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(ncols=3, nrows=3, figsize=(30, 30), constrained_layout=True)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].axhline(y = bias, color = 'k', linestyle = '--')\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_train_real,\n",
    "    **features_info,\n",
    "    ax=ax,\n",
    "    **common_params,\n",
    ")\n",
    "#plt.axhline(y = 0.5, color = 'b', linestyle = '-')\n",
    "\n",
    "_ = display.figure_.suptitle(\n",
    "    \"Partial dependence of the census data\",\n",
    "    fontsize=40,\n",
    ")\n",
    "fn = f'../data/Subject{sub}/ML{sub}ValueDependence.png'\n",
    "# plt.savefig(fn,format ='png', bbox_inches=\"tight\",dpi = 300)\n",
    "\n",
    "print(\"Computing partial dependence corrs...\")\n",
    "features_info = {\n",
    "    # features of interest\n",
    "    \"features\": [('Age','Hours per Week')] + combos,#topfeat,\n",
    "    # type of partial dependence plot\n",
    "    \"kind\": \"average\",\n",
    "    # information regarding categorical features\n",
    "    \"categorical_features\": catFeatures,\n",
    "}\n",
    "_, ax = plt.subplots(ncols=2, nrows=2, figsize=(20, 20), constrained_layout=True)\n",
    "display = PartialDependenceDisplay.from_estimator(\n",
    "    model,\n",
    "    X_train_real,\n",
    "    **features_info,\n",
    "    ax=ax,\n",
    "    **common_params,\n",
    ")\n",
    "_ = display.figure_.suptitle(\n",
    "    f\"ML Partial dependence pairings\",\n",
    "    fontsize=40,\n",
    ")\n",
    "fn = f'../data/Subject{sub}/ML{sub}PairDependence.png'\n",
    "# plt.savefig(fn,format ='png', bbox_inches=\"tight\",dpi = 300)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = test_importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(f\"Permutation Importances ML Test Set\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.figure.tight_layout()\n",
    "fn =f'../data/Subject{sub}/ML{sub}_Test_Perm_Imp.png'\n",
    "# plt.savefig(fn,format = 'png',dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "test_importances.to_csv('../data/Subject'+sub+'/test_imp_ml'+sub+'.csv')\n",
    "train_importances.to_csv('../data/Subject'+sub+'/train_imp_ml'+sub+'.csv')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = train_importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(f\"Permutation Importances ML Train Set\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.figure.tight_layout()\n",
    "fn =f'../data/Subject{sub}/ML{sub}_Train_Perm_Imp.png'\n",
    "# plt.savefig(fn,format = 'png',dpi = 300)\n",
    "plt.show()\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for fold, (train, test) in enumerate(cv.split(x, y_real)):\n",
    "    model.fit(x.iloc[train], y_real[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        model,\n",
    "        x.iloc[test],\n",
    "        y[test],\n",
    "        alpha=0.3,\n",
    "        lw=1,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=r\"$\\pm$ 1 std. dev.\",\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"Mean ROC curve with variability (On Answers)\",\n",
    ")\n",
    "ax.axis(\"square\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.gcf()\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "handles = handles[-3:]\n",
    "labels = labels[-3:]\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "fn =f'../data/Subject{sub}/{sub}_MLROC_Curve.png'\n",
    "# plt.savefig(fn,format = 'png',dpi = 300)\n",
    "plt.show()\n",
    "\n",
    "subdata['ML Mean TPR'] = mean_tpr\n",
    "subdata['ML Mean AUC'] = mean_auc\n",
    "subdata['ML STD AUC'] = std_auc\n",
    "subdata['ML STD TPR'] = std_tpr\n",
    "subdata['ML Upper TPR'] = tprs_upper\n",
    "subdata['ML Lower TPR'] = tprs_lower\n",
    "subdata['ML PD'] = ml_pd\n",
    "subdata['ML bias'] = bias\n",
    "from hdf5storage import loadmat, savemat\n",
    "outpath = f'../data/Subject{sub}/'\n",
    "outname = f'Sub{sub}MLPredictions.hdf'\n",
    "savemat(outpath+outname,subdata,store_python_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b901fda-c392-456e-90eb-739f78d50e27",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Extra snippets for fixing error in old dataset, delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b2d66-7c4f-4d11-8526-720a7639e00b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy when trained and tested on smaller dataset: 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "'''Adds model cross validated predictions'''\n",
    "model_ind = pd.DataFrame()\n",
    "y_trpred = cross_val_predict(model, X_train_real, y_train_real, cv=3)\n",
    "y_tepred = cross_val_predict(model, X_test_real, y_test_real, cv=3)\n",
    "tr_ind = np.array(X_train.index)\n",
    "te_ind = np.array(X_test.index)\n",
    "y_pred = np.concatenate((y_trpred,y_tepred))\n",
    "indss = np.concatenate((tr_ind,te_ind))\n",
    "model_ind['Index'] = indss\n",
    "model_ind['Model'] = y_pred\n",
    "model_ind = model_ind.sort_values(by=['Index'])\n",
    "sub_df['Model'] = np.array(model_ind['Model'])\n",
    "fn = f'data/Subject{sub}/Subject{sub}Full.csv'\n",
    "# sub_df.to_csv(fn,index = False) ### \n",
    "model_ind = model_ind.reset_index(drop = True)\n",
    "ipad = 0\n",
    "for ses in ['1','2']:\n",
    "    if ses == '2':\n",
    "        ipad = trrange\n",
    "    fl = f'data/Subject{sub}/{sub}_Session_{ses}_Dataset.csv'\n",
    "    subses = pd.read_csv(fl)\n",
    "    trrange = len(subses)\n",
    "    subses['Model'] = np.array(model_ind['Model'][ipad:trrange+ipad])\n",
    "    #subses.to_csv(fl,index = False)\n",
    "    #print(ipad,trrange)\n",
    "sub_df['Model']\n",
    "model_accuracy  = (np.array(model_ind['Model']) == np.array(sub_df['Real Answer'])).sum()/len(np.array(model_ind['Model']) == np.array(sub_df['Real Answer']))\n",
    "print(f'The model\\'s accuracy when trained and tested on smaller dataset: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5fbe8-9c12-4287-b455-ee55580cf75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
